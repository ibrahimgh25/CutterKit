{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diamonds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibrahimgh25/CutterKit/blob/master/diamonds_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGRM33V7ETA8"
      },
      "source": [
        "In this file I try out differnt ML algorithms provided by sklean on a diamond database provided by Kaggle. I initially tried solving this problem with a loosely designed keras model (the first deeplearning model I code), but the results were really bad. After a while, I read a part of the book \"Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\" April 2017 for the author Aurlien Gron. So I was curious to test the effeciency of the algorithms the author talked about (RandomForest, SVM, and RandomTree)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnsFhDXjrgjx"
      },
      "source": [
        "# Classic imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0kFDNukmv05"
      },
      "source": [
        "The diamond database is a database of about 54000 samples of diamonds. Each sample (row) contains 10 features (columns). The features are: number of carats, x(length), y(width), z(depth), color, cut quality, clarity, weight, and price - which will be treated as our target.\n",
        "For more information about the database please refer to the kaggle website it was obatained from (https://www.kaggle.com/shivam2503/diamonds)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNdRwH4lPJlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503f5738-88b8-403e-e375-94117007c981"
      },
      "source": [
        "# The original database has an unnamed column for indexing, we'll just delete that\n",
        "diamonds = pd.read_csv('diamonds.csv').drop('Unnamed: 0', axis=1)\n",
        "diamonds.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   carat    53940 non-null  float64\n",
            " 1   cut      53940 non-null  object \n",
            " 2   color    53940 non-null  object \n",
            " 3   clarity  53940 non-null  object \n",
            " 4   depth    53940 non-null  float64\n",
            " 5   table    53940 non-null  float64\n",
            " 6   price    53940 non-null  int64  \n",
            " 7   x        53940 non-null  float64\n",
            " 8   y        53940 non-null  float64\n",
            " 9   z        53940 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrLEyS_asUzq"
      },
      "source": [
        "sklearn is a great tool for machine learning and we'll import a lot of stuff from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNBThLxtQo0d"
      },
      "source": [
        "# For splitting the database\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For creating a custom class (DataFrameSelector)\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "# For dealing encoding the categorical attributes and data standarization\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "# For creating a pipline for data preparation\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "# The machine learning algorithms\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZio3d0St3M1"
      },
      "source": [
        "We'll split the database into an 80/20 train/dev sets. I know a lot of people prefer to name the sets train/test, but I heard once Dr. Andrew Ng (from deeplearning.ai) giving an argument for why train/dev is a better convention and I was convinced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr8IRCOCtM1t",
        "outputId": "284ee320-2cee-4fc5-c6c1-e1aaf7c31153"
      },
      "source": [
        "diamonds_train, diamonds_dev = train_test_split(diamonds, random_state=42, test_size=0.15)\n",
        "print(diamonds_train.head())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       carat        cut color clarity  depth  table  price     x     y     z\n",
            "13713   0.30      Ideal     E     VS2   62.3   56.0    603  4.27  4.30  2.67\n",
            "3481    0.81      Ideal     G     VS2   61.5   55.0   3397  6.00  6.06  3.71\n",
            "343     0.71  Very Good     E     VS2   64.0   57.0   2804  5.66  5.68  3.63\n",
            "22822   1.55  Very Good     E     SI1   62.4   58.0  10851  7.36  7.42  4.61\n",
            "51658   0.30      Ideal     G     VS2   61.2   55.0    545  4.35  4.38  2.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPl5UpyoptLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b322f8-1502-497c-dd07-d7222eab940c"
      },
      "source": [
        "# Define the numerical and categorical attributes for the database.\n",
        "diamonds_features = diamonds.drop('price', axis=1)\n",
        "num_attribs = diamonds_features.drop(['cut', 'color', 'clarity'], axis=1).columns\n",
        "cat_attribs = diamonds_features.drop(num_attribs, axis=1).columns\n",
        "\n",
        "print(num_attribs)\n",
        "print(cat_attribs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['carat', 'depth', 'table', 'x', 'y', 'z'], dtype='object')\n",
            "Index(['cut', 'color', 'clarity'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIjg2VfEq9ng"
      },
      "source": [
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "  ''' This class will be used in the pipeline to select columns from the \n",
        "  database. The class inherits from the BaseEstimator and TranformerMixin classes\n",
        "  so it should have a fit method and a transform method.\n",
        "  Args:\n",
        "    attribute_names (:obj:'list' of :obj:'str'): the list of columns\n",
        "     (attributes) to be selected by the class object.\n",
        "  '''\n",
        "  def __init__(self, attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "  def fit(self, X, y=None):\n",
        "    # Just return self, this one doesn't need fitting.\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    # Just return the values in the specified columns in X.\n",
        "    return X[self.attribute_names].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwdvhbGXxbl_"
      },
      "source": [
        "The next cell defines the pipelines to be used for data preparation, which are:\n",
        "1. num_pipeline: used to prepare the numerical attributes, it selects them then apply StandardScaler\n",
        "2. cat_pipeline: used to prepare the categorical attributes, it selects them, then applies a OneHotEncoder on them.\n",
        "3. full_pipeline: uses FeatureUnion to combine the two pipelines into one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSNrk51r29Q"
      },
      "source": [
        "num_pipeline = Pipeline([\n",
        " ('selector', DataFrameSelector(num_attribs)),\n",
        " ('std_scaler', StandardScaler()),\n",
        " ])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        " ('selector', DataFrameSelector(cat_attribs)),\n",
        " ('1hot_encoder', OneHotEncoder()),\n",
        " ])\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        " (\"num_pipeline\", num_pipeline),\n",
        " (\"cat_pipeline\", cat_pipeline),\n",
        " ]) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtSLmkcsN2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52ed7d4-2ea4-46e2-ab57-31f87c0a49a5"
      },
      "source": [
        "# Let's create our Xs and ys\n",
        "X_train = full_pipeline.fit_transform(diamonds_train)\n",
        "y_train = diamonds_train['price']\n",
        "X_dev = full_pipeline.transform(diamonds_dev)\n",
        "y_dev = diamonds_dev['price']\n",
        "print(type(X_train), type(y_train))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'> <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02GXNGr-ygj0"
      },
      "source": [
        "The next cell contains a helper function to be used for training and evaluating the different algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UtrYNQsNy5"
      },
      "source": [
        "def eval_model(X_train, y_train, X_dev, y_dev, model):\n",
        "  '''This function that will make it easy to train multiple algorithms\n",
        "  Parameters:\n",
        "    X_train: the features to be used for training\n",
        "    y_train: the targets to be used for training\n",
        "    X_dev: the features to be used to evaluate the model (from the dev set)\n",
        "    y_dev: the target to be used to evaluate the model(from the dev set)\n",
        "    model: the model to be trained and evaluated\n",
        "  Returns the trained_model, the training_error, and the dev error.\n",
        "  '''\n",
        "  model.fit(X_train, y_train)\n",
        "  y_predict = model.predict(X_train)\n",
        "  training_error = mean_squared_error(y_train, y_predict)\n",
        "  y_predict = model.predict(X_dev)\n",
        "  dev_error = mean_squared_error(y_dev, y_predict)\n",
        "  return model, training_error, dev_error"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-THa1oA1t9N"
      },
      "source": [
        "forest_reg, training_error, dev_error = eval_model(X_train, y_train, X_dev, y_dev, RandomForestRegressor())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYcuRSNsYDih"
      },
      "source": [
        "results = []\n",
        "results.append(('forest_reg', training_error, dev_error))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAm7jd1_Yd5q"
      },
      "source": [
        "linearsvc_reg = LinearSVC(penalty='l2', C=1.0, dual=False)\n",
        "linearsvc_reg, training_error, dev_error = eval_model(X_train, y_train, X_dev, y_dev, linearsvc_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpn2P0cnDCrT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}