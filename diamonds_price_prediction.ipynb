{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diamonds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibrahimgh25/CutterKit/blob/master/diamonds_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGRM33V7ETA8"
      },
      "source": [
        "In this file I try out differnt ML algorithms provided by sklean on a diamond database provided by Kaggle. I initially tried solving this problem with a loosely designed keras model (the first deeplearning model I code), but the results were really bad. After a while, I read a part of the book \"Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\" April 2017 for the author Aurlien Gron. So I was curious to test the effeciency of the algorithms the author talked about (RandomForest, SVM, and RandomTree)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnsFhDXjrgjx"
      },
      "source": [
        "# Classic imports\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0kFDNukmv05"
      },
      "source": [
        "The diamond database is a database of about 54000 samples of diamonds. Each sample (row) contains 10 features (columns). The features are: number of carats, x(length), y(width), z(depth), color, cut quality, clarity, weight, and price - which will be treated as our target.\n",
        "For more information about the database please refer to the kaggle website it was obatained from (https://www.kaggle.com/shivam2503/diamonds)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNdRwH4lPJlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503f5738-88b8-403e-e375-94117007c981"
      },
      "source": [
        "# The original database has an unnamed column for indexing, we'll just delete that\n",
        "diamonds = pd.read_csv('diamonds.csv').drop('Unnamed: 0', axis=1)\n",
        "diamonds.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   carat    53940 non-null  float64\n",
            " 1   cut      53940 non-null  object \n",
            " 2   color    53940 non-null  object \n",
            " 3   clarity  53940 non-null  object \n",
            " 4   depth    53940 non-null  float64\n",
            " 5   table    53940 non-null  float64\n",
            " 6   price    53940 non-null  int64  \n",
            " 7   x        53940 non-null  float64\n",
            " 8   y        53940 non-null  float64\n",
            " 9   z        53940 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrLEyS_asUzq"
      },
      "source": [
        "sklearn is a great tool for machine learning and we'll import a lot of stuff from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNBThLxtQo0d"
      },
      "source": [
        "# For splitting the database\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For creating a custom class (DataFrameSelector)\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "# For dealing encoding the categorical attributes and data standarization\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "# For creating a pipline for data preparation\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "# The machine learning algorithms\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZio3d0St3M1"
      },
      "source": [
        "We'll split the database into an 80/20 train/dev sets. I know a lot of people prefer to name the sets train/test, but I heard once Dr. Andrew Ng (from deeplearning.ai) giving an argument for why train/dev is a better convention and I was convinced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr8IRCOCtM1t",
        "outputId": "3f043439-8f67-48b9-d742-b06a99bae122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "diamonds_train, diamonds_dev = train_test_split(diamonds, random_state=42, test_size=0.2)\n",
        "print(diamonds_train.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       carat        cut color clarity  depth  table  price     x     y     z\n",
            "26546   2.01       Good     F     SI2   58.1   64.0  16231  8.23  8.19  4.77\n",
            "9159    1.01  Very Good     E     SI2   60.0   60.0   4540  6.57  6.49  3.92\n",
            "14131   1.10    Premium     H     VS2   62.5   58.0   5729  6.59  6.54  4.10\n",
            "15757   1.50       Good     E     SI2   61.5   65.0   6300  7.21  7.17  4.42\n",
            "24632   1.52  Very Good     G     VS1   62.1   57.0  12968  7.27  7.32  4.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPl5UpyoptLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b322f8-1502-497c-dd07-d7222eab940c"
      },
      "source": [
        "# Define the numerical and categorical attributes for the database.\n",
        "diamonds_features = diamonds.drop('price', axis=1)\n",
        "num_attribs = diamonds_features.drop(['cut', 'color', 'clarity'], axis=1).columns\n",
        "cat_attribs = diamonds_features.drop(num_attribs, axis=1).columns\n",
        "\n",
        "print(num_attribs)\n",
        "print(cat_attribs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['carat', 'depth', 'table', 'x', 'y', 'z'], dtype='object')\n",
            "Index(['cut', 'color', 'clarity'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIjg2VfEq9ng"
      },
      "source": [
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "  ''' This class will be used in the pipeline to select columns from the \n",
        "  database. The class inherits from the BaseEstimator and TranformerMixin classes\n",
        "  so it should have a fit method and a transform method.\n",
        "  Args:\n",
        "    attribute_names (:obj:'list' of :obj:'str'): the list of columns\n",
        "     (attributes) to be selected by the class object.\n",
        "  '''\n",
        "  def __init__(self, attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "  def fit(self, X, y=None):\n",
        "    # Just return self, this one doesn't need fitting.\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    # Just return the values in the specified columns in X.\n",
        "    return X[self.attribute_names].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwdvhbGXxbl_"
      },
      "source": [
        "The next cell defines the pipelines to be used for data preparation, which are:\n",
        "1. num_pipeline: used to prepare the numerical attributes, it selects them then apply StandardScaler\n",
        "2. cat_pipeline: used to prepare the categorical attributes, it selects them, then applies a OneHotEncoder on them.\n",
        "3. full_pipeline: uses FeatureUnion to combine the two pipelines into one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSNrk51r29Q"
      },
      "source": [
        "num_pipeline = Pipeline([\n",
        " ('selector', DataFrameSelector(num_attribs)),\n",
        " ('std_scaler', StandardScaler()),\n",
        " ])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        " ('selector', DataFrameSelector(cat_attribs)),\n",
        " ('1hot_encoder', OneHotEncoder()),\n",
        " ])\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        " (\"num_pipeline\", num_pipeline),\n",
        " (\"cat_pipeline\", cat_pipeline),\n",
        " ]) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtSLmkcsN2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58db17d8-7746-4309-8b89-dc0fd1f08500"
      },
      "source": [
        "# Let's create our Xs and ys\n",
        "X_train = full_pipeline.fit_transform(diamonds_train)\n",
        "y_train = diamonds_train['price']\n",
        "X_dev = full_pipeline.transform(diamonds_dev)\n",
        "y_dev = diamonds_dev['price']\n",
        "print(type(X_train), type(y_train))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'> <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02GXNGr-ygj0"
      },
      "source": [
        "The next cell contains a helper function to be used for training and evaluating the different algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UtrYNQsNy5"
      },
      "source": [
        "def eval_model(X_train, y_train, X_dev, y_dev, model):\n",
        "  '''This function that will make it easy to train multiple algorithms\n",
        "  Parameters:\n",
        "    X_train: the features to be used for training\n",
        "    y_train: the targets to be used for training\n",
        "    X_dev: the features to be used to evaluate the model (from the dev set)\n",
        "    y_dev: the target to be used to evaluate the model(from the dev set)\n",
        "    model: the model to be trained and evaluated\n",
        "  Returns the trained_model, the training_error, and the dev error.\n",
        "  '''\n",
        "  model.fit(X_train, y_train)\n",
        "  y_predict = model.predict(X_train)\n",
        "  training_error = mean_squared_error(y_train, y_predict)\n",
        "  y_predict = model.predict(X_dev)\n",
        "  dev_error = mean_squared_error(y_dev, y_predict)\n",
        "  return model, training_error, dev_error"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-THa1oA1t9N"
      },
      "source": [
        "forest_reg, training_error, dev_error = eval_model(X_train, y_train, X_dev, y_dev, RandomForestRegressor())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYcuRSNsYDih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dad825f-26b7-41c0-fdff-09176b04f595"
      },
      "source": [
        "print(np.sqrt(dev_error))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "551.3810690765001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAm7jd1_Yd5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebe20b1c-5e5d-41a6-b7f3-b56f44c16406"
      },
      "source": [
        "X_test = full_pipeline.transform(diamonds_test)\n",
        "y_test = diamonds_test['price'].values\n",
        "\n",
        "y_predicted = forest_reg.predict(X_test)\n",
        "mean_absolute_error(y_predicted, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "265.42200216927296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDEdbY15bNKF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fbc5fb16-400c-41c1-9df9-95d3266d7977"
      },
      "source": [
        "print('predicted: ', list(y_predicted[-5:]))\n",
        "print('actual: ', y_test[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-23a6dc32b772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_predicted' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl8uFPoBsyrN"
      },
      "source": [
        "\n",
        "\n",
        "linearsvc_reg = LinearSVC(penalty='l2', C=1.0, dual=False)\n",
        "linearsvc_reg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}